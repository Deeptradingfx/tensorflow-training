{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are similar to \"ordinary\" Neural Networks: they are made up of neurons that have learnable weights and biases. These neurons receive some inputs, performs a dot product and optionally follows it with a non-linearity. The whole network expresses a single differentiable score function: from the raw image pixels on one end to class scores at the other. And they have a loss function (e.g. SVM/Softmax) on the last (fully-connected) layer.\n",
    "\n",
    "So how is it different from other neural networks? ConvNet architectures assume that the inputs are images, which allows us to encode certain properties into the architecture. These parameters then make the forward function more efficient to implement, and vastly reduce the amount of parameters in the network.\n",
    "\n",
    "Now, from the previous session, Softmax Regression for MNIST classification, getting a 92% accuracy on the MNIST is bad. This session is meant for fixing that. Shifting from a very simple model to a sophisticated one: a small convolutional neural network. This will reach an accuracy of around 99.2% -- no state of the art, but it is something.\n",
    "\n",
    "Here is a diagram of the model we are going to build (created with TensorBoard):\n",
    "\n",
    "![](../figures/mnist_deep_graph.png)\n",
    "\n",
    "### Weight and Bias Initialization\n",
    "\n",
    "To implement this model, we are going to create a lot of weights and biases. The weights should be initialized to prevent 0 gradients (in simple terms, gradients could be described as \"flow\" of learning). To avoid \"dead neurons\", it is a good practice to initialize positive bias. Lastly, instead of repeatedly initializing weights and biases, we may write two functions to do it for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the TensorFlow library\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "    \n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Architecture\n",
    "\n",
    "CNNs are currently the state-of-the-art model for image classification tasks. CNNs apply a series of filters to the raw pixel data of an image, to extract and to learn high-level features, which the model can use for classification. CNNs contain three components:\n",
    "\n",
    "* __Convolutional layers__ apply a specified number of filters to the image. For each image subregion, this layer performs a set of mathematical operations to produce a single value in the output feature map (simply, a value to represent that subregion).\n",
    "\n",
    "* __Pooling layers__ reduce the size of the image data based on the filters applied by the convolutional layer, to reduce processing time of the network. The most common pooling algorithm used is max pooling, which extracts the maximum value in a subregion of the feature map.\n",
    "\n",
    "* __Dense (fully-connected) layers__ perform the classification on the features extracted by the convolutional layer and reduced by the pooling layers.\n",
    "\n",
    "Typically, a CNN is composed of a stack of convolutional modules that perform feature extraction. Each module consists of a convolutional layer followed by a pooling layer. The last convolutional module is followed by one or more dense layers to perform classification. The final dense layer in a CNN contains a single node for each target class in the model, conventionally with a softmax function to generate a probability distribution for each node. The softmax values for a given image can be interpreted as how likely that the image belongs to a target class.\n",
    "\n",
    "For this session, the following CNN architecture shall be implemented:\n",
    "\n",
    "1. Convolutional layer #1. Applying 32 5x5 filters (extracting 5x5-pixel subregions), with ReLU activation function.\n",
    "2. Pooling layer #1. Performs max pooling with a 2x2 filter and a stride of 2 (which specifies that pooled regions do not overlap).\n",
    "3. Convolutional layer #2. Applies 64 5x5 filters, with ReLu activation function.\n",
    "4. Pooling layer #2. Again, performs max pooling with a 2x2 filter and a stride of 2.\n",
    "5. Dense layer #1. 1,024 neurons, with dropout regularization rate of 0.4 (probability that any given elemtn will be dropped during training).\n",
    "6. Dense layer #2. 10 neurons, one for each digit target class (0-9).\n",
    "\n",
    "First, let us import our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/darth/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting /home/darth/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/darth/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/darth/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('/home/darth/MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, let us define the input placeholders. One for the training data, `x`, and one for the actual labels, `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, 784], name='x_input')\n",
    "\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, 10], name='actual_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before building the specified architecture, let us define the functions to build the convolutional layer and pooling layer, so that we will not have to repeat our actions of defining them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, w):\n",
    "    return tf.nn.conv2d(x, w, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On to building the CNN architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First conv layer\n",
    "w_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, w_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Second conv layer\n",
    "w_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, w_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Fully-connected layer (dense layer)\n",
    "w_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 * 64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, w_fc1) + b_fc1)\n",
    "\n",
    "# Droput regularization\n",
    "# To reduce overfitting, apply dropout before the readout layer\n",
    "keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Readout layer\n",
    "# Layer that produces the classification,\n",
    "# like Softmax regression from the previous session\n",
    "w_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_ = tf.matmul(h_fc1_drop, w_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Softmax as the activation layer, with cross-entropy for measuring the model's loss. To train the model, `Adam` will be used with a learning rate of `1e-4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_))\n",
    "train_op = tf.train.AdamOptimizer(learning_rate=1e-4).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For measuring the accuracy of the model,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, dtype=tf.float16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start training the defined model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0, training accuracy : 0.1199951171875\n",
      "step : 100, training accuracy : 0.85986328125\n",
      "step : 200, training accuracy : 0.9599609375\n",
      "step : 300, training accuracy : 0.93994140625\n",
      "step : 400, training accuracy : 0.93994140625\n",
      "step : 500, training accuracy : 0.8798828125\n",
      "step : 600, training accuracy : 0.919921875\n",
      "step : 700, training accuracy : 0.919921875\n",
      "step : 800, training accuracy : 1.0\n",
      "step : 900, training accuracy : 0.93994140625\n",
      "step : 1000, training accuracy : 0.93994140625\n",
      "step : 1100, training accuracy : 0.97998046875\n",
      "step : 1200, training accuracy : 0.97998046875\n",
      "step : 1300, training accuracy : 0.9599609375\n",
      "step : 1400, training accuracy : 0.89990234375\n",
      "step : 1500, training accuracy : 0.93994140625\n",
      "step : 1600, training accuracy : 0.97998046875\n",
      "step : 1700, training accuracy : 0.97998046875\n",
      "step : 1800, training accuracy : 0.9599609375\n",
      "step : 1900, training accuracy : 0.97998046875\n",
      "step : 2000, training accuracy : 0.97998046875\n",
      "step : 2100, training accuracy : 1.0\n",
      "step : 2200, training accuracy : 0.97998046875\n",
      "step : 2300, training accuracy : 0.97998046875\n",
      "step : 2400, training accuracy : 0.97998046875\n",
      "step : 2500, training accuracy : 0.97998046875\n",
      "step : 2600, training accuracy : 0.9599609375\n",
      "step : 2700, training accuracy : 1.0\n",
      "step : 2800, training accuracy : 0.97998046875\n",
      "step : 2900, training accuracy : 0.97998046875\n",
      "step : 3000, training accuracy : 0.9599609375\n",
      "step : 3100, training accuracy : 1.0\n",
      "step : 3200, training accuracy : 1.0\n",
      "step : 3300, training accuracy : 1.0\n",
      "step : 3400, training accuracy : 0.9599609375\n",
      "step : 3500, training accuracy : 0.97998046875\n",
      "step : 3600, training accuracy : 0.97998046875\n",
      "step : 3700, training accuracy : 1.0\n",
      "step : 3800, training accuracy : 0.97998046875\n",
      "step : 3900, training accuracy : 1.0\n",
      "step : 4000, training accuracy : 0.9599609375\n",
      "step : 4100, training accuracy : 0.97998046875\n",
      "step : 4200, training accuracy : 0.9599609375\n",
      "step : 4300, training accuracy : 1.0\n",
      "step : 4400, training accuracy : 0.93994140625\n",
      "step : 4500, training accuracy : 1.0\n",
      "step : 4600, training accuracy : 1.0\n",
      "step : 4700, training accuracy : 1.0\n",
      "step : 4800, training accuracy : 0.97998046875\n",
      "step : 4900, training accuracy : 0.97998046875\n",
      "step : 5000, training accuracy : 1.0\n",
      "step : 5100, training accuracy : 0.97998046875\n",
      "step : 5200, training accuracy : 1.0\n",
      "step : 5300, training accuracy : 0.97998046875\n",
      "step : 5400, training accuracy : 1.0\n",
      "step : 5500, training accuracy : 0.97998046875\n",
      "step : 5600, training accuracy : 1.0\n",
      "step : 5700, training accuracy : 0.97998046875\n",
      "step : 5800, training accuracy : 0.97998046875\n",
      "step : 5900, training accuracy : 0.97998046875\n",
      "step : 6000, training accuracy : 1.0\n",
      "step : 6100, training accuracy : 0.9599609375\n",
      "step : 6200, training accuracy : 1.0\n",
      "step : 6300, training accuracy : 1.0\n",
      "step : 6400, training accuracy : 1.0\n",
      "step : 6500, training accuracy : 0.97998046875\n",
      "step : 6600, training accuracy : 1.0\n",
      "step : 6700, training accuracy : 1.0\n",
      "step : 6800, training accuracy : 0.97998046875\n",
      "step : 6900, training accuracy : 1.0\n",
      "step : 7000, training accuracy : 1.0\n",
      "step : 7100, training accuracy : 1.0\n",
      "step : 7200, training accuracy : 1.0\n",
      "step : 7300, training accuracy : 0.97998046875\n",
      "step : 7400, training accuracy : 1.0\n",
      "step : 7500, training accuracy : 0.97998046875\n",
      "step : 7600, training accuracy : 0.97998046875\n",
      "step : 7700, training accuracy : 1.0\n",
      "step : 7800, training accuracy : 1.0\n",
      "step : 7900, training accuracy : 1.0\n",
      "step : 8000, training accuracy : 1.0\n",
      "step : 8100, training accuracy : 1.0\n",
      "step : 8200, training accuracy : 1.0\n",
      "step : 8300, training accuracy : 1.0\n",
      "step : 8400, training accuracy : 0.97998046875\n",
      "step : 8500, training accuracy : 1.0\n",
      "step : 8600, training accuracy : 1.0\n",
      "step : 8700, training accuracy : 0.97998046875\n",
      "step : 8800, training accuracy : 1.0\n",
      "step : 8900, training accuracy : 0.97998046875\n",
      "step : 9000, training accuracy : 1.0\n",
      "step : 9100, training accuracy : 1.0\n",
      "step : 9200, training accuracy : 1.0\n",
      "step : 9300, training accuracy : 0.97998046875\n",
      "step : 9400, training accuracy : 1.0\n",
      "step : 9500, training accuracy : 1.0\n",
      "step : 9600, training accuracy : 1.0\n",
      "step : 9700, training accuracy : 1.0\n",
      "step : 9800, training accuracy : 1.0\n",
      "step : 9900, training accuracy : 1.0\n",
      "step : 10000, training accuracy : 1.0\n",
      "step : 10100, training accuracy : 1.0\n",
      "step : 10200, training accuracy : 1.0\n",
      "step : 10300, training accuracy : 1.0\n",
      "step : 10400, training accuracy : 1.0\n",
      "step : 10500, training accuracy : 1.0\n",
      "step : 10600, training accuracy : 1.0\n",
      "step : 10700, training accuracy : 1.0\n",
      "step : 10800, training accuracy : 1.0\n",
      "step : 10900, training accuracy : 0.97998046875\n",
      "step : 11000, training accuracy : 1.0\n",
      "step : 11100, training accuracy : 1.0\n",
      "step : 11200, training accuracy : 1.0\n",
      "step : 11300, training accuracy : 0.97998046875\n",
      "step : 11400, training accuracy : 1.0\n",
      "step : 11500, training accuracy : 1.0\n",
      "step : 11600, training accuracy : 1.0\n",
      "step : 11700, training accuracy : 1.0\n",
      "step : 11800, training accuracy : 1.0\n",
      "step : 11900, training accuracy : 1.0\n",
      "step : 12000, training accuracy : 1.0\n",
      "step : 12100, training accuracy : 1.0\n",
      "step : 12200, training accuracy : 1.0\n",
      "step : 12300, training accuracy : 1.0\n",
      "step : 12400, training accuracy : 1.0\n",
      "step : 12500, training accuracy : 1.0\n",
      "step : 12600, training accuracy : 0.97998046875\n",
      "step : 12700, training accuracy : 1.0\n",
      "step : 12800, training accuracy : 1.0\n",
      "step : 12900, training accuracy : 1.0\n",
      "step : 13000, training accuracy : 1.0\n",
      "step : 13100, training accuracy : 1.0\n",
      "step : 13200, training accuracy : 1.0\n",
      "step : 13300, training accuracy : 0.97998046875\n",
      "step : 13400, training accuracy : 0.97998046875\n",
      "step : 13500, training accuracy : 1.0\n",
      "step : 13600, training accuracy : 1.0\n",
      "step : 13700, training accuracy : 1.0\n",
      "step : 13800, training accuracy : 1.0\n",
      "step : 13900, training accuracy : 1.0\n",
      "step : 14000, training accuracy : 1.0\n",
      "step : 14100, training accuracy : 1.0\n",
      "step : 14200, training accuracy : 1.0\n",
      "step : 14300, training accuracy : 1.0\n",
      "step : 14400, training accuracy : 1.0\n",
      "step : 14500, training accuracy : 1.0\n",
      "step : 14600, training accuracy : 1.0\n",
      "step : 14700, training accuracy : 1.0\n",
      "step : 14800, training accuracy : 1.0\n",
      "step : 14900, training accuracy : 1.0\n",
      "step : 15000, training accuracy : 1.0\n",
      "step : 15100, training accuracy : 1.0\n",
      "step : 15200, training accuracy : 1.0\n",
      "step : 15300, training accuracy : 1.0\n",
      "step : 15400, training accuracy : 1.0\n",
      "step : 15500, training accuracy : 1.0\n",
      "step : 15600, training accuracy : 1.0\n",
      "step : 15700, training accuracy : 1.0\n",
      "step : 15800, training accuracy : 1.0\n",
      "step : 15900, training accuracy : 1.0\n",
      "step : 16000, training accuracy : 1.0\n",
      "step : 16100, training accuracy : 1.0\n",
      "step : 16200, training accuracy : 1.0\n",
      "step : 16300, training accuracy : 1.0\n",
      "step : 16400, training accuracy : 1.0\n",
      "step : 16500, training accuracy : 1.0\n",
      "step : 16600, training accuracy : 1.0\n",
      "step : 16700, training accuracy : 1.0\n",
      "step : 16800, training accuracy : 1.0\n",
      "step : 16900, training accuracy : 0.97998046875\n",
      "step : 17000, training accuracy : 1.0\n",
      "step : 17100, training accuracy : 1.0\n",
      "step : 17200, training accuracy : 1.0\n",
      "step : 17300, training accuracy : 1.0\n",
      "step : 17400, training accuracy : 1.0\n",
      "step : 17500, training accuracy : 1.0\n",
      "step : 17600, training accuracy : 1.0\n",
      "step : 17700, training accuracy : 1.0\n",
      "step : 17800, training accuracy : 1.0\n",
      "step : 17900, training accuracy : 1.0\n",
      "step : 18000, training accuracy : 1.0\n",
      "step : 18100, training accuracy : 1.0\n",
      "step : 18200, training accuracy : 1.0\n",
      "step : 18300, training accuracy : 1.0\n",
      "step : 18400, training accuracy : 1.0\n",
      "step : 18500, training accuracy : 1.0\n",
      "step : 18600, training accuracy : 1.0\n",
      "step : 18700, training accuracy : 1.0\n",
      "step : 18800, training accuracy : 1.0\n",
      "step : 18900, training accuracy : 1.0\n",
      "step : 19000, training accuracy : 1.0\n",
      "step : 19100, training accuracy : 1.0\n",
      "step : 19200, training accuracy : 1.0\n",
      "step : 19300, training accuracy : 1.0\n",
      "step : 19400, training accuracy : 1.0\n",
      "step : 19500, training accuracy : 1.0\n",
      "step : 19600, training accuracy : 1.0\n",
      "step : 19700, training accuracy : 1.0\n",
      "step : 19800, training accuracy : 1.0\n",
      "step : 19900, training accuracy : 1.0\n",
      "Test Accuracy : 0.9921875\n"
     ]
    }
   ],
   "source": [
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    for index in range(20000):\n",
    "        # train by batch size of 50\n",
    "        batch_x, batch_y = mnist.train.next_batch(50)\n",
    "        \n",
    "        # input data to train operation\n",
    "        feed_dict = {x: batch_x, y: batch_y, keep_prob:0.5}\n",
    "        \n",
    "        # run the training operation with the previously-defined input\n",
    "        sess.run(train_op, feed_dict=feed_dict)\n",
    "        \n",
    "        # show training accuracy every 100 steps\n",
    "        if index % 100 == 0: \n",
    "            # do not perform dropout\n",
    "            feed_dict = {x: batch_x, y: batch_y, keep_prob: 1.0}\n",
    "            \n",
    "            train_accuracy = sess.run(accuracy, feed_dict=feed_dict)\n",
    "            \n",
    "            print('step : {}, training accuracy : {}'.format(index, train_accuracy))\n",
    "        \n",
    "        # input data for model testing\n",
    "    feed_dict = {x: mnist.test.images, y: mnist.test.labels, keep_prob: 1.0}\n",
    "        \n",
    "    test_accuracy = sess.run(accuracy, feed_dict=feed_dict)\n",
    "        \n",
    "    # display the accuracy of the model\n",
    "    # on unseen data, i.e. validation\n",
    "    print('Test Accuracy : {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the final test accuracy is approximately 99.2%."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
